{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Adarsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows',None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('augmented_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Adarsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Adarsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50768it [19:34, 43.24it/s] \n"
     ]
    }
   ],
   "source": [
    "num_classes = 5\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(150, 200, 3)),\n",
    "    MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load and preprocess images\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "target_size = (200, 150)  # Width, Height\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    img = cv.imread(row['image_id'])\n",
    "    \n",
    "    # resizing images\n",
    "    resized_img = cv.resize(img, target_size)\n",
    "\n",
    "    # min-max normalization\n",
    "    normalized_image = resized_img / 255.0\n",
    "\n",
    "    X.append(normalized_image)\n",
    "    y.append(row['label'])\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "X = X.reshape(X.shape + (1,))\n",
    "\n",
    "# Convert labels to one-hot encoded vectors\n",
    "y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Adarsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Adarsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1270/1270 [==============================] - 384s 296ms/step - loss: 1.5352 - accuracy: 0.2383 - val_loss: 1.5238 - val_accuracy: 0.2391\n",
      "Epoch 2/10\n",
      "1270/1270 [==============================] - 270s 213ms/step - loss: 1.5243 - accuracy: 0.2377 - val_loss: 1.5213 - val_accuracy: 0.2391\n",
      "Epoch 3/10\n",
      "1270/1270 [==============================] - 271s 213ms/step - loss: 1.5239 - accuracy: 0.2341 - val_loss: 1.5210 - val_accuracy: 0.2360\n",
      "Epoch 4/10\n",
      "1270/1270 [==============================] - 259s 204ms/step - loss: 1.5239 - accuracy: 0.2395 - val_loss: 1.5216 - val_accuracy: 0.2360\n",
      "Epoch 5/10\n",
      "1270/1270 [==============================] - 253s 199ms/step - loss: 1.5236 - accuracy: 0.2389 - val_loss: 1.5243 - val_accuracy: 0.2360\n",
      "Epoch 6/10\n",
      "1270/1270 [==============================] - 257s 202ms/step - loss: 1.5236 - accuracy: 0.2378 - val_loss: 1.5217 - val_accuracy: 0.2363\n",
      "Epoch 7/10\n",
      "1270/1270 [==============================] - 251s 198ms/step - loss: 1.5236 - accuracy: 0.2393 - val_loss: 1.5219 - val_accuracy: 0.2363\n",
      "Epoch 8/10\n",
      "1270/1270 [==============================] - 255s 201ms/step - loss: 1.5236 - accuracy: 0.2327 - val_loss: 1.5218 - val_accuracy: 0.2360\n",
      "Epoch 9/10\n",
      "1270/1270 [==============================] - 255s 201ms/step - loss: 1.5235 - accuracy: 0.2373 - val_loss: 1.5219 - val_accuracy: 0.2360\n",
      "Epoch 10/10\n",
      "1270/1270 [==============================] - 252s 198ms/step - loss: 1.5234 - accuracy: 0.2346 - val_loss: 1.5209 - val_accuracy: 0.2391\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss and validation loss\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert one-hot encoded vectors to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred_classes))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
